#!/usr/bin/env python3
"""
arXivè®ºæ–‡ä¿¡æ¯æµç¨‹åº
ç‹¬ç«‹äºGitHubé¡¹ç›®ç³»ç»Ÿï¼Œæ¯å¤©ä¸‹åˆ4:00ï¼ˆ16:00ï¼‰è‡ªåŠ¨è¿è¡Œ
è·å–AI/MLé¢†åŸŸæœ€æ–°è®ºæ–‡ï¼Œå‘é€ç»™è®¢é˜…ç”¨æˆ·
"""

import os
import sys
import json
import datetime
import yagmail
import arxiv
from typing import List, Dict
import requests

# å¯¼å…¥ç°æœ‰é…ç½®
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def get_today_str() -> str:
    """è¿”å›å½“å‰æ—¥æœŸå­—ç¬¦ä¸²"""
    return datetime.datetime.now().strftime('%Y-%m-%d')

def scrape_arxiv_papers(categories: List[str] = None, max_results: int = 20) -> List[Dict]:
    """
    ä»arXivçˆ¬å–æŒ‡å®šç±»åˆ«çš„æœ€æ–°è®ºæ–‡
    
    Args:
        categories: arXivç±»åˆ«åˆ—è¡¨ï¼Œå¦‚['cs.AI', 'cs.LG', 'cs.CL', 'cs.CV', 'stat.ML']
        max_results: æœ€å¤§è·å–æ•°é‡
        
    Returns:
        è®ºæ–‡ä¿¡æ¯åˆ—è¡¨
    """
    if categories is None:
        categories = ['cs.AI', 'cs.LG', 'cs.CL', 'cs.CV', 'stat.ML']
    
    print(f"ğŸš€ å¼€å§‹çˆ¬å–arXivè®ºæ–‡ï¼Œç±»åˆ«: {categories}")
    
    # æ„å»ºæŸ¥è¯¢å­—ç¬¦ä¸²
    query_parts = []
    for cat in categories:
        query_parts.append(f'cat:{cat}')
    query = ' OR '.join(query_parts)
    
    # æœç´¢æœ€æ–°è®ºæ–‡
    client = arxiv.Client()
    search = arxiv.Search(
        query=query,
        max_results=max_results,
        sort_by=arxiv.SortCriterion.SubmittedDate,
        sort_order=arxiv.SortOrder.Descending
    )
    
    papers = []
    try:
        for result in client.results(search):
            paper = {
                'id': result.entry_id.split('/')[-1],
                'title': result.title,
                'authors': [str(author) for author in result.authors],
                'summary': result.summary,
                'published': result.published.strftime('%Y-%m-%d %H:%M:%S'),
                'updated': result.updated.strftime('%Y-%m-%d %H:%M:%S') if result.updated else '',
                'pdf_url': result.pdf_url,
                'primary_category': result.primary_category if hasattr(result, 'primary_category') else '',
                'categories': result.categories if hasattr(result, 'categories') else [],
                'comment': result.comment if hasattr(result, 'comment') and result.comment else '',
                'journal_ref': result.journal_ref if hasattr(result, 'journal_ref') and result.journal_ref else ''
            }
            papers.append(paper)
            print(f"  å·²è·å–: {paper['title'][:50]}...")
            
    except Exception as e:
        print(f"âŒ arXivçˆ¬å–å¤±è´¥: {e}")
    
    print(f"âœ… æˆåŠŸè·å– {len(papers)} ç¯‡è®ºæ–‡")
    return papers

def select_top_papers(papers: List[Dict], top_n: int = 10) -> List[Dict]:
    """
    ç²¾é€‰top_nç¯‡è®ºæ–‡
    åŸºäºï¼šæ–°é²œåº¦ã€æ ‡é¢˜é‡è¦æ€§ã€æ‘˜è¦å®Œæ•´æ€§
    """
    if len(papers) <= top_n:
        return papers
    
    # ç®€å•ç­›é€‰ï¼šä¼˜å…ˆè€ƒè™‘ä»Šå¤©æˆ–æ˜¨å¤©çš„è®ºæ–‡
    today = datetime.datetime.now().date()
    selected = []
    others = []
    
    for paper in papers:
        try:
            paper_date = datetime.datetime.strptime(paper['published'][:10], '%Y-%m-%d').date()
            days_old = (today - paper_date).days
            if days_old <= 2:
                selected.append((days_old, paper))
            else:
                others.append((days_old, paper))
        except:
            others.append((99, paper))
    
    # æŒ‰æ–°é²œåº¦æ’åº
    selected.sort(key=lambda x: x[0])
    others.sort(key=lambda x: x[0])
    
    # ç»„åˆç»“æœ
    result = []
    for days_old, paper in selected:
        result.append(paper)
        if len(result) >= top_n:
            break
    
    if len(result) < top_n:
        for days_old, paper in others:
            result.append(paper)
            if len(result) >= top_n:
                break
    
    return result

def get_ai_analysis(papers: List[Dict]) -> str:
    """
    ä½¿ç”¨æ™ºè°±AIåˆ†æè®ºæ–‡è¶‹åŠ¿
    
    Args:
        papers: è®ºæ–‡åˆ—è¡¨
        
    Returns:
        AIåˆ†ææŠ¥å‘Š
    """
    api_key = os.environ.get('ZHIPUAI_API_KEY')
    if not api_key:
        print("âš ï¸ æœªè®¾ç½®ZHIPUAI_API_KEYç¯å¢ƒå˜é‡ï¼Œè·³è¿‡AIåˆ†æ")
        return "ä»Šæ—¥arXivè®ºæ–‡ç²¾é€‰"
    
    # æ„å»ºè®ºæ–‡æ‘˜è¦
    papers_summary = ""
    for i, paper in enumerate(papers[:5], 1):  # åªå–å‰5ç¯‡è¿›è¡Œåˆ†æ
        papers_summary += f"{i}. {paper['title']}\n   æ‘˜è¦: {paper['summary'][:200]}...\n"
    
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªAIç ”ç©¶ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹arXivè®ºæ–‡å¹¶å›ç­”ï¼š
1. è¿™äº›è®ºæ–‡ä¸»è¦é›†ä¸­åœ¨å“ªäº›ç ”ç©¶ä¸»é¢˜ï¼Ÿ
2. æœ‰ä»€ä¹ˆæŠ€æœ¯çªç ´æˆ–åˆ›æ–°ç‚¹ï¼Ÿ
3. å¯¹AI/MLé¢†åŸŸçš„å‘å±•æœ‰ä»€ä¹ˆå¯ç¤ºï¼Ÿ
4. ç”¨ç®€æ´çš„ä¸­æ–‡æ€»ç»“ä»Šæ—¥AIç ”ç©¶è¶‹åŠ¿ã€‚

è®ºæ–‡åˆ—è¡¨ï¼š
{papers_summary}

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒç®€æ´ä¸“ä¸šã€‚"""
    
    try:
        from zhipuai import ZhipuAI
        client = ZhipuAI(api_key=api_key)
        response = client.chat.completions.create(
            model="glm-4-flash",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1000,
            temperature=0.7
        )
        analysis = response.choices[0].message.content.strip()
        print("âœ… AIåˆ†æå®Œæˆ")
        return analysis
    except Exception as e:
        print(f"âŒ AIåˆ†æå¤±è´¥: {e}")
        return "ä»Šæ—¥arXivè®ºæ–‡è¶‹åŠ¿ï¼šAI/MLé¢†åŸŸæŒç»­å¿«é€Ÿå‘å±•ï¼Œå…³æ³¨å¤§æ¨¡å‹ã€å¤šæ¨¡æ€ã€å¼ºåŒ–å­¦ä¹ ç­‰å‰æ²¿æ–¹å‘ã€‚"

def translate_and_summarize(text: str, max_length: int = 150) -> str:
    """
    ä½¿ç”¨æ™ºè°±AIç¿»è¯‘å¹¶ç²¾ç®€æ–‡æœ¬
    
    Args:
        text: è‹±æ–‡æ–‡æœ¬
        max_length: æœ€å¤§é•¿åº¦
        
    Returns:
        ç¿»è¯‘å¹¶ç²¾ç®€åçš„ä¸­æ–‡æ–‡æœ¬
    """
    api_key = os.environ.get('ZHIPUAI_API_KEY')
    if not api_key:
        return text[:max_length] + "..." if len(text) > max_length else text
    
    try:
        from zhipuai import ZhipuAI
        client = ZhipuAI(api_key=api_key)
        
        prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡è®ºæ–‡æ‘˜è¦ç¿»è¯‘æˆä¸­æ–‡ï¼Œå¹¶ç²¾ç®€åˆ°{max_length}å­—ä»¥å†…ï¼š
        
{text}

è¦æ±‚ï¼š
1. å‡†ç¡®ç¿»è¯‘ä¸“ä¸šæœ¯è¯­
2. ä¿æŒå­¦æœ¯ä¸¥è°¨æ€§
3. ç²¾ç®€æ‘˜è¦ï¼Œçªå‡ºæ ¸å¿ƒè´¡çŒ®
4. è¾“å‡ºçº¯ä¸­æ–‡æ–‡æœ¬ï¼Œä¸åŠ å¼•å·æˆ–é¢å¤–è¯´æ˜"""

        response = client.chat.completions.create(
            model="glm-4-flash",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=500,
            temperature=0.3
        )
        translated = response.choices[0].message.content.strip()
        
        # è¿›ä¸€æ­¥ç²¾ç®€
        if len(translated) > max_length:
            # ç®€å•æˆªæ–­ï¼Œä¿ç•™å®Œæ•´å¥å­
            sentences = translated.split('ã€‚')
            result = []
            current_length = 0
            for sent in sentences:
                if sent:
                    sent_with_period = sent + 'ã€‚'
                    if current_length + len(sent_with_period) <= max_length:
                        result.append(sent_with_period)
                        current_length += len(sent_with_period)
                    else:
                        break
            translated = ''.join(result)
            if not translated:
                translated = translated[:max_length] + "..."
        
        return translated
    except Exception as e:
        print(f"âš ï¸ ç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡æœ¬: {e}")
        # å›é€€ï¼šç®€å•æˆªå–
        return text[:max_length] + "..." if len(text) > max_length else text

def format_paper_email(papers: List[Dict], analysis: str = "") -> str:
    """
    æ ¼å¼åŒ–è®ºæ–‡é‚®ä»¶å†…å®¹ï¼ˆç®€æ´ç¿»è¯‘ç‰ˆï¼‰
    
    Args:
        papers: è®ºæ–‡åˆ—è¡¨
        analysis: AIåˆ†æç»“æœ
        
    Returns:
        æ ¼å¼åŒ–åçš„é‚®ä»¶å†…å®¹
    """
    today = get_today_str()
    content = f"""ğŸš€ arXiv AI/MLè®ºæ–‡ç²¾é€‰ - {today} {datetime.datetime.now().strftime('%H:%M')}
{"="*60}

ğŸ“š ä»Šæ—¥ç²¾é€‰ï¼ˆ{len(papers)}ç¯‡ï¼‰ï¼š
{"="*60}

"""
    
    for i, paper in enumerate(papers, 1):
        # æå–ä½œè€…å§“æ°
        authors = paper['authors']
        if len(authors) > 2:
            author_str = f"{authors[0].split()[-1]} ç­‰"  # å–å§“æ°
        else:
            # åªå–å§“æ°
            author_names = [a.split()[-1] for a in authors[:2]]
            author_str = ", ".join(author_names)
        
        # æ¸…ç†æ ‡é¢˜
        title = paper['title'].replace('\n', ' ')
        
        # ç¿»è¯‘å¹¶ç²¾ç®€æ‘˜è¦
        summary_en = paper['summary']
        summary_cn = translate_and_summarize(summary_en, max_length=120)
        
        content += f"""{i}. ã€{paper['primary_category']}ã€‘{title}
    ğŸ‘¤ {author_str} | ğŸ“… {paper['published'][:10]}
    ğŸ“– {summary_cn}
    ğŸ”— https://arxiv.org/abs/{paper['id']}
    
"""
    
    content += f"""{"="*60}

ğŸ’¡ è¶‹åŠ¿åˆ†æï¼š
{analysis}

{"="*60}

ğŸ¤– æˆ‘æ˜¯è°¢å°æœï¼Œopenclawæœºå™¨äººï¼Œè°¢è‹¹æœçš„æ•°å­—å‘˜å·¥ã€‚
ğŸ“¬ æ­¤é‚®ä»¶æ¯å¤©ä¸‹åˆ4ç‚¹è‡ªåŠ¨å‘é€ï¼ŒåŒæ­¥åˆ°GitHubå­˜æ¡£ã€‚

"""
    
    return content

def send_email(content: str, to: str = None, subject: str = None) -> bool:
    """
    å‘é€é‚®ä»¶
    
    Args:
        content: é‚®ä»¶å†…å®¹
        to: æ”¶ä»¶äººï¼Œé»˜è®¤ä¸ºç”¨æˆ·é‚®ç®±
        subject: é‚®ä»¶ä¸»é¢˜
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    # è·å–é‚®ç®±é…ç½®
    email = '19121220286@163.com'
    pwd = os.environ.get('WANGYI_EMAIL_AUTH')
    
    if not pwd:
        print("âŒ æœªè®¾ç½®WANGYI_EMAIL_AUTHç¯å¢ƒå˜é‡")
        return False
    
    # è®¾ç½®æ”¶ä»¶äºº
    if to is None:
        to = 'pxxhl@qq.com'  # ç”¨æˆ·é‚®ç®±
    
    if subject is None:
        today = get_today_str()
        subject = f"ğŸš€ arXiv AI/MLè®ºæ–‡ç²¾é€‰ - {today} {datetime.datetime.now().strftime('%H:%M:%S')}"
    
    try:
        # å‘é€é‚®ä»¶
        yag = yagmail.SMTP(email, pwd, host='smtp.163.com')
        yag.send(to=to, subject=subject, contents=content)
        print(f"âœ… é‚®ä»¶å·²å‘é€åˆ°: {to}")
        return True
    except Exception as e:
        print(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")
        return False

def send_to_all_subscribers(content: str, subject: str = None) -> bool:
    """
    å‘é€ç»™æ‰€æœ‰è®¢é˜…ç”¨æˆ·
    """
    emails_file = 'emails.txt'
    if not os.path.exists(emails_file):
        print(f"âš ï¸ è®¢é˜…åˆ—è¡¨ä¸å­˜åœ¨: {emails_file}")
        return False
    
    try:
        with open(emails_file, 'r', encoding='utf-8') as f:
            emails = [line.strip() for line in f if line.strip()]
    except Exception as e:
        print(f"âŒ è¯»å–è®¢é˜…åˆ—è¡¨å¤±è´¥: {e}")
        return False
    
    print(f"ğŸ“§ å‡†å¤‡å‘é€ç»™ {len(emails)} ä¸ªè®¢é˜…ç”¨æˆ·")
    
    # ç”¨æˆ·è¦æ±‚ç«‹å³ç¾¤å‘ç»™æ‰€æœ‰ç”¨æˆ·
    success_count = 0
    for i, email in enumerate(emails, 1):
        print(f"  æ­£åœ¨å‘é€ ({i}/{len(emails)}) â†’ {email}")
        if send_email(content, to=email, subject=subject):
            success_count += 1
            if i < len(emails):  # ä¸æ˜¯æœ€åä¸€ä¸ª
                import time
                time.sleep(2)  # é¿å…å‘é€è¿‡å¿«è¢«é™åˆ¶
    
    print(f"ğŸ“Š å‘é€å®Œæˆ: {success_count}/{len(emails)} æˆåŠŸ")
    return success_count > 0

def daily_task():
    """æ¯æ—¥ä»»åŠ¡ï¼šçˆ¬å–ã€åˆ†æã€å‘é€"""
    print(f"ğŸ“… {get_today_str()} arXivè®ºæ–‡ä¿¡æ¯æµä»»åŠ¡å¼€å§‹...")
    
    # 1. çˆ¬å–è®ºæ–‡
    papers = scrape_arxiv_papers(
        categories=['cs.AI', 'cs.LG', 'cs.CL', 'cs.CV', 'stat.ML'],
        max_results=25
    )
    
    if not papers:
        print("âŒ æœªè·å–åˆ°è®ºæ–‡ï¼Œä»»åŠ¡ç»ˆæ­¢")
        return False
    
    # 2. ç²¾é€‰10ç¯‡
    selected_papers = select_top_papers(papers, top_n=10)
    print(f"ğŸ¯ ç²¾é€‰ {len(selected_papers)} ç¯‡è®ºæ–‡")
    
    # 3. AIåˆ†æ
    analysis = get_ai_analysis(selected_papers)
    
    # 4. æ ¼å¼åŒ–é‚®ä»¶
    content = format_paper_email(selected_papers, analysis)
    
    # 5. å‘é€é‚®ä»¶
    today = get_today_str()
    subject = f"ğŸš€ arXiv AI/MLè®ºæ–‡ç²¾é€‰ - {today} {datetime.datetime.now().strftime('%H:%M:%S')}"
    success = send_to_all_subscribers(content, subject)
    
    # 6. ä¿å­˜æ—¥å¿—
    log_file = f"arxiv_logs/{get_today_str()}.txt"
    os.makedirs(os.path.dirname(log_file), exist_ok=True)
    with open(log_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… arXivè®ºæ–‡ä»»åŠ¡å®Œæˆï¼Œæ—¥å¿—ä¿å­˜åˆ°: {log_file}")
    return success

def test_immediate():
    """ç«‹å³æµ‹è¯•å‘é€"""
    print("âš¡ ç«‹å³æµ‹è¯•arXivè®ºæ–‡ä¿¡æ¯æµ...")
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs('arxiv_logs', exist_ok=True)
    
    # æ‰§è¡Œä»»åŠ¡
    success = daily_task()
    
    if success:
        print("ğŸ‰ æµ‹è¯•æˆåŠŸï¼è¯·æ£€æŸ¥é‚®ç®±")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥")
    
    return success

def run_scheduled():
    """å®šæ—¶è¿è¡Œæ¨¡å¼"""
    import schedule
    import time
    
    print("â° arXivè®ºæ–‡ä¿¡æ¯æµå®šæ—¶æœåŠ¡å¯åŠ¨...")
    print("ğŸ“… é…ç½®ï¼šæ¯å¤©16:00 (CST) è‡ªåŠ¨æ‰§è¡Œ")
    
    # è®¾ç½®å®šæ—¶ä»»åŠ¡
    schedule.every().day.at("16:00").do(daily_task)
    
    # ç«‹å³æ‰§è¡Œä¸€æ¬¡ï¼ˆç°åœ¨16:04ï¼Œè¡¥å‘ä»Šå¤©çš„ï¼‰
    print("ğŸš€ ç«‹å³æ‰§è¡Œä»Šå¤©16:00çš„ä»»åŠ¡...")
    daily_task()
    
    print("âœ… arXivå®šæ—¶æœåŠ¡å·²å¯åŠ¨ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡æ‰§è¡Œ...")
    
    # ä¿æŒè¿è¡Œ
    while True:
        schedule.run_pending()
        time.sleep(60)

if __name__ == "__main__":
    # ç«‹å³æ‰§è¡Œæµ‹è¯•å¹¶å¯åŠ¨å®šæ—¶æœåŠ¡
    print("="*60)
    print("ğŸš€ arXivè®ºæ–‡ä¿¡æ¯æµ v1.0 - ç«‹å³éƒ¨ç½²")
    print("="*60)
    
    # ç«‹å³æ‰§è¡Œä¸€æ¬¡ï¼ˆç¾¤å‘ç»™æ‰€æœ‰ç”¨æˆ·ï¼‰
    test_immediate()
    
    # å¯åŠ¨å®šæ—¶æœåŠ¡
    print("\n" + "="*60)
    print("âš™ï¸ å¯åŠ¨å®šæ—¶æœåŠ¡...")
    print("="*60)
    run_scheduled()